{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["![Data Dunkers Banner](https://github.com/PS43Foundation/data-dunkers/blob/main/docs/top-banner.jpg?raw=true)\n\n<a href=\"https://hub.callysto.ca/jupyter/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fdata-dunkers%2Fdata-dunkers-modules&branch=main&subPath=AI/image-recognition.ipynb&depth=1\" target=\"_parent\"><img src=\"https://raw.githubusercontent.com/callysto/curriculum-notebooks/master/open-in-callysto-button.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Callysto\"/></a><a href=\"https://colab.research.google.com/github/data-dunkers/data-dunkers-modules/blob/mainAI/image-recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg?sanitize=true\" width=\"123\" height=\"24\" alt=\"Open in Colab\"/></a>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Machine Learning - Image Recognition"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Objectives\n", "\n", "Students will be able to:\n", "\n", "- train an artificial intelligence model to recognize objects in images"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Training an AI\n", "\n", "We are going to train an AI system to recognize if an image contains a basketball or a hoop. We'll use images that are [public domain](https://en.wikipedia.org/wiki/Public_domain) or [Creative Commons](https://creativecommons.org/) because we are allowed to use them without purchasing a license.\n", "\n", "The more examples you have, the better the AI will be able to discriminate between basketballs and hoops.\n", "\n", "1. Create two new folders on your computer, one called `basketball` and one called `hoop`.\n", "1. Find and download at least 10 images of basketballs from [Pexels](https://www.pexels.com/search/basketball/) or [Pixabay](https://pixabay.com/images/search/basketball/). Put them in your `basketball` folder.\n", "1. Find and download at least 10 images of hoops (without basketballs) from [Pexels](https://www.pexels.com/search/basketball%20hoop/) or [Pixabay](https://pixabay.com/images/search/basketball%20hoop/). Put them in your `hoop` folder.\n", "\n", "## Teaching the Machine\n", "\n", "1. Open [Teachable Machine image training](https://teachablemachine.withgoogle.com/train/image)\n", "1. Rename `Class 1` as `basketball`, and `Class 2` as `hoop` by clicking on the pencil icons.\n", "1. Upload your basketball images to the `basketball` class and your hoop images to the `hoop` class.\n", "1. Click the `Train model` button.\n", "1. After the training has finished, click the `Export Model` button, click the `Tensorflow Lite` tab on the right, then click the `Download my model` button. The button will change to `Converting model...` and it will take a few minutes, don't click away from that browser tab.\n", "1. Your model should then download automatically as `converted_tflite.zip`.\n", "1. Upload your `converted_tflite.zip` file to [the folder that this notebook is in](.) on Callysto Hub or wherever you are running this notebook.\n", "\n", "After you have completed all of those steps, run the following cell to set up the image classifier. Run the following code cell."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["try:\n", "    import tflite_runtime.interpreter as tflite\n", "except:\n", "    !pip install tflite-runtime --user\n", "    import tflite_runtime.interpreter as tflite\n", "from zipfile import ZipFile\n", "from PIL import Image, ImageOps\n", "import numpy as np\n", "import requests, urllib.request, os\n", "import pandas as pd\n", "from IPython.display import clear_output, display\n", "clear_output()\n", "\n", "try:\n", "    with ZipFile('converted_tflite.zip', 'r') as zip_object:\n", "        zip_object.extractall()\n", "except:\n", "    print('Unable to find your converted_tflite.zip file, using online version')\n", "    r = requests.get('https://raw.githubusercontent.com/callysto/data-files/main/data-science-and-artificial-intelligence/converted_tflite.zip')\n", "    with open('converted_tflite.zip', 'wb') as f:\n", "        f.write(r.content)\n", "    with ZipFile('converted_tflite.zip', 'r') as zip_object:\n", "        zip_object.extractall()\n", "interpreter = tflite.Interpreter('model_unquant.tflite')\n", "interpreter.allocate_tensors()\n", "input_details = interpreter.get_input_details()\n", "output_details = interpreter.get_output_details()\n", "input_shape = input_details[0]['shape']\n", "\n", "class_names = open('labels.txt', 'r').readlines()\n", "os.remove('model_unquant.tflite')\n", "os.remove('labels.txt')\n", "\n", "def classify_image(image_url, show_image=False):\n", "    filename = image_url.split('/')[-1]\n", "    r = requests.get(image_url, stream=True)\n", "    with open(filename, 'wb') as f:\n", "        f.write(r.content)\n", "    image = Image.open(filename).convert('RGB')\n", "    image = image.resize((input_shape[1], input_shape[2]))\n", "    if show_image:\n", "        display(image)\n", "    os.remove(filename)\n", "    input_data = (np.expand_dims(np.array(image), axis=0) / 255.0).astype(np.float32)\n", "    interpreter.set_tensor(input_details[0]['index'], input_data)\n", "    interpreter.invoke()\n", "    output_data = interpreter.get_tensor(output_details[0]['index'])\n", "    predicted_class = np.argmax(output_data)\n", "    predicted_class_name = class_names[predicted_class].strip()[2:]\n", "    confidence_level = output_data[0][predicted_class]\n", "    return predicted_class_name, confidence_level, image\n", "\n", "clear_output()\n", "print('Model imported and classify_image(image_url) function defined')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The function will return a classification and confidence level, and a resized version of the image.\n", "\n", "Now that we have set up the `classify_image()` function, we can load an image from a link and get its classification according to our trained AI.\n", "\n", "Change the string in the `image_url` variable to be a direct link to an online image.\n", "\n", "**Make sure you have copied the `image address` and that it is not a link to a webpage. The url should end with something like `.jpg`, `.gif`, or `.png`**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_url = 'https://cdn.pixabay.com/photo/2022/11/22/20/25/ball-7610545_960_720.jpg'\n", "\n", "results = classify_image(image_url)\n", "results"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The first value returned is the classification, in our case `basketball` or `hoop`.\n", "\n", "The second is \"confidence score\" which is how sure the AI is of that classification, `1` means `100%` confident.\n", "\n", "The third value is the downloaded and resized image."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results[2]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can even use this to categorize a list of online images. We'll try it with some art rather than photos and see how it performs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["urls = [\n", "    'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ1fwaHscZxxXAkA6eH5GUn03UkH9XMW2q52GwHXKv6gq2nEAVvA9stY8T-GFNwQD12UJU&usqp=CAU',\n", "    'https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/465429d0-de8d-40a9-b0a3-3dc78ddb97f0/d9wp266-2bda803e-3204-4f80-8ab6-b41b3883e881.jpg/v1/fill/w_1024,h_640,q_75,strp/basketball_crosshatch_by_kevindoesart_d9wp266-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NjQwIiwicGF0aCI6IlwvZlwvNDY1NDI5ZDAtZGU4ZC00MGE5LWIwYTMtM2RjNzhkZGI5N2YwXC9kOXdwMjY2LTJiZGE4MDNlLTMyMDQtNGY4MC04YWI2LWI0MWIzODgzZTg4MS5qcGciLCJ3aWR0aCI6Ijw9MTAyNCJ9XV0sImF1ZCI6WyJ1cm46c2VydmljZTppbWFnZS5vcGVyYXRpb25zIl19.LRyck_AJEKQF8lDdfqI9Eff1yaKpIGZyZ_xW_bSPIjg',\n", "    'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSUx7cdLTk77jS7ostVtHw37zTZXeTMNpMHU9uZ_kWPc8MQqKcz6wZfFKe19fBk3L5oOLM&usqp=CAU',\n", "    'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSSI-anNAclWOCdQTcS3nPx-BpmvwmuQZriKboLSBesZpz8un9olo2HWrVhhjVRnQgfZXU&usqp=CAU',\n", "]\n", "\n", "data = pd.DataFrame(urls, columns=['url'])\n", "labels = []\n", "confidences = []\n", "images = []\n", "\n", "for url in urls:\n", "    results = classify_image(url, True)\n", "    labels.append(results[0])\n", "    confidences.append(results[1])\n", "    images.append(results[2])\n", "\n", "data['label'] = labels\n", "data['confidence'] = confidences\n", "data['image'] = images\n", "\n", "for index, row in data.iterrows():\n", "    display(row['image'])\n", "    print(row['label'], row['confidence'])\n", "    print('-----------------------------')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If the model is not accurately identifying the objects, you can go back to the start of this notebook and train it with more images.\n", "\n", "Of course we can also use this same process to train an AI model to categorize images of other things, for example identifying if something is a soup, salad, or sandwich."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.4"}}, "nbformat": 4, "nbformat_minor": 2}