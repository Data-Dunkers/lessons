{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataDunkers.ca Banner](https://github.com/Data-Dunkers/lessons/blob/main/images/top-banner.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Predicting NBA Positions\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this notebook we will:\n",
    "\n",
    "- use the [sklearn](https://scikit-learn.org/stable/index.html) library to create, train, understand, and test basic machine-learning models\n",
    "- ientify potential sources of error in datasets, and fix them before training machine-learning models\n",
    "- explore ways to improve model accuracy\n",
    "\n",
    "## Introduction\n",
    "\n",
    "[Machine learning](https://simple.wikipedia.org/wiki/Machine_learning) (ML) is the study of using data and algorithms for computers to learn. By analyzing large amounts of data, computers can identify patterns and make decisions with minimal human intervention. \n",
    "\n",
    "Imagine you have a lot of information about NBA players, like how many points they score, how many rebounds they get, and how many assists they make. With machine learning, we can teach a computer to look at these stats and predict what position a player might play, like a guard, forward, or center. \n",
    "\n",
    "It's like giving the computer a bunch of clues and letting it figure out the answer! This can be helpful for coaches and teams to understand their players better and make smarter decisions during games.\n",
    "\n",
    "## Import Libraries and Data\n",
    "\n",
    "Let's begin by importing the libraries and data we'll be using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nba_player_stats = pd.read_csv('20232024nbaplayerstatsreg.csv', encoding='latin1')\n",
    "nba_player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have the names of NBA players with their stats for the 2023-2024 NBA season.\n",
    "\n",
    "Let's take a look at all the different columns in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of an NBA game, each column in our dataset represents specific statistics about a player's performance. For example, `Rk` is the player's rank, `Player` is the player's name, `Pos` is their position, and so on. In machine learning, we'll use these columns as \"features\" for our model.\n",
    "\n",
    "**Features** are individual measurable properties or characteristics of the data that help the model make predictions. In this case, the player's stats will be our features, and we'll use them to predict an NBA player's position.\n",
    "\n",
    "## Cleaning Data\n",
    "\n",
    "We saw multiple instances of a player named \"Precious Achiuwa\" in the dataset, so we will want to remove those duplicate entries.\n",
    "\n",
    "**Data cleaning** is the process of fixing or removing incorrect, corrupted, or irrelevant data from a dataset. This ensures that the data is accurate and ready for analysis or machine learning tasks.\n",
    "\n",
    "Let's search for `'Precious Achiuwa'` in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats.loc[nba_player_stats['Player'] == 'Precious Achiuwa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make it so that every player in this dataset is only represented once.\n",
    "\n",
    "In order to achieve this, we'll find any players that played for multiple teams and drop any rows that are not their total stats (`TOT`). First let's look at all of the affected players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for player in nba_player_stats[nba_player_stats['Tm'] == 'TOT']['Player']:\n",
    "    display(nba_player_stats[nba_player_stats['Player'] == player])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the `TOT` row is always first, so let's [drop_duplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) and keep only the first of the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats = nba_player_stats.drop_duplicates(subset=['Player'], keep='first')\n",
    "nba_player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, let's check if there is only one instance of \"Precious Achiuwa\" in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats.loc[nba_player_stats['Player'] == 'Precious Achiuwa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another potential problem in our machine-learning model are players with few statistics in the NBA. Players with few statistics often have incomplete or less representative data, which can skew the model's learning process. These outliers may introduce noise (random or unpredictable fluctuations) and reduce the overall accuracy of the model.\n",
    "\n",
    "To solve this issue, let's set a parameter that a player needs at least `6` points. This will help our model to learn more accurate patterns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats = nba_player_stats[nba_player_stats['PTS'] > 6].reset_index(drop=True)\n",
    "nba_player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, one last thing we want to do for our model is to check out the possible positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats['Pos'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify, we'll map the following as guards (**G**):\n",
    "\n",
    "* points guards (PG)\n",
    "* shooting guards (SG)\n",
    "* PG-SG\n",
    "* SF-SG\n",
    "\n",
    "And map the following as forwards (**F**):\n",
    "\n",
    "* small-forwards (SF)\n",
    "* power-forwards (PF)\n",
    "* SF-PF\n",
    "* PF-C\n",
    "* C-PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_mapping = {'PG': 'G', 'SG': 'G', 'PG-SG': 'G', 'SF-SG': 'G', 'PF': 'F', 'SF': 'F', 'SF-PF': 'F', 'PF-C': 'F', 'C-PF': 'F'}\n",
    "\n",
    "nba_player_stats['Pos'] = nba_player_stats['Pos'].map(position_mapping).fillna(nba_player_stats['Pos'])\n",
    "nba_player_stats = nba_player_stats.reset_index(drop=True)\n",
    "nba_player_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to make sure we just have three possible positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_player_stats['Pos'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "You don't have to know the specific coding details of creating our model but understand the generic model of what is going on to replicate similar models in your own projects.\n",
    "\n",
    "### Selecting Features and Target\n",
    "\n",
    "`features` is a list of columns that represent different statistics of the players. These are the inputs to our model.\n",
    "\n",
    "`target` is the column we want to predict, which in this case is the player's position ('Pos').\n",
    "\n",
    "### Splitting Data\n",
    "\n",
    "`X` contains the feature data (player stats), and is usually represented by `X` in machine-learning.\n",
    "\n",
    "`y` contains the target data (player positions), and is usually represented by `y` in machine-learning.\n",
    "\n",
    "We then split our data into two portions of testing data `(X_test, y_test)` and two portions of training data `(X_train, y_train)`.\n",
    "\n",
    "### Training the Model\n",
    "\n",
    "`RandomForestClassifier` is the machine learning algorithm we selected for this particular problem. You don't need to know the specifics of how the model works, but it essentially creates a \"forest\" of decision trees and combines their predictions for better accuracy.\n",
    "\n",
    "`model.fit(X_train, y_train)` then trains the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['FG%', '3P', '3PA', '3P%', '2P%', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "target = 'Pos'\n",
    "\n",
    "X = nba_player_stats[features]\n",
    "y = nba_player_stats[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model and Finding our Accuracy\n",
    "\n",
    "`model.predict(X_test)` uses the trained model to predict player positions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model scoring at 50% accuracy means that 50% of the time it can correctly identify an NBA player's position.\n",
    "\n",
    "Using the `classification_report`, we can find more details on our model's accuracy, specifically in regard to how well it scores in guessing particular positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is okay for our first instance of a machine learning model, but one way to potentially improve our model is to see which hyper-parameters we can tweak in our model. \n",
    "\n",
    "Once again, you just need to know enough of what this does to implement similar methods in your own models. This code cell may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 200],'max_depth': [None, 10, 20, 30],'min_samples_split': [2, 5, 10],'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "model = RandomForestClassifier(random_state=10)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Best model accuracy: {accuracy:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means if we wanted to implement these changes we would use the following code to initialize our model:\n",
    "\n",
    "```python\n",
    "best_model = RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100, random_state=10)\n",
    "```\n",
    "\n",
    "But in our case it wouldn't make much difference to the accuracy.\n",
    "\n",
    "## Using the Model\n",
    "\n",
    "Let's test our model with [Pascal Siakam](https://www.nba.com/stats/player/1627783?SeasonType=Regular+Season)'s stats from the [2022-2023 regular season](https://www.basketball-reference.com/players/s/siakapa01.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "ps_stats = pd.DataFrame({\n",
    "    'FG%': [0.48], \n",
    "    '3P': [1.3], \n",
    "    '3PA': [4.0], \n",
    "    '3P%': [0.324], \n",
    "    '2P%': [0.523], \n",
    "    'FT%': [0.774], \n",
    "    'ORB': [1.8], \n",
    "    'DRB': [6.0], \n",
    "    'TRB': [7.8], \n",
    "    'AST': [5.8], \n",
    "    'STL': [0.9], \n",
    "    'BLK': [0.5], \n",
    "    'TOV': [2.4], \n",
    "    'PF': [3.2], \n",
    "    'PTS': [24.2]})\n",
    "model.predict(ps_stats)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pascal Siakam played Power Forward for the Raptors in the 2022-2023 season, so our model's prediction was accurate.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the process of building and optimizing a machine learning model to predict NBA player positions based on their game statistics. We started with data cleaning and feature selection to ensure our dataset was ready to be used in a machine-learning model. We then trained a `RandomForestClassifier` model using our cleaned dataset, and explored improving the model's accuracy by identifying the best hyper-parameters.\n",
    "\n",
    "In your projects, find datasets that have useful features that can be used in the context of \"prediction\". There are loads of different ways you can implement machine learning in Python. If you're interested in developing more machine-learning models using `sklearn`, you can find more information on [their official website](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Data Dunkers License](https://github.com/Data-Dunkers/lessons/blob/main/images/bottom-banner.jpg?raw=true)](https://github.com/Data-Dunkers/lessons/blob/main/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
