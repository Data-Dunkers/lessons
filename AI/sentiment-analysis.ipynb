{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5kaQ3L2z0E9"
      },
      "source": [
        "![DataDunkers.ca Banner](https://github.com/Data-Dunkers/lessons/blob/main/images/top-banner.jpg?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4W5IzoVz0FB"
      },
      "source": [
        "# Artificial Intelligence - Sentiment Analysis\n",
        "\n",
        "## Objectives\n",
        "\n",
        "Students will be able to:\n",
        "\n",
        "- use the [nltk](https://www.nltk.org/) library to implement sentiment analysis in Python\n",
        "- identify ways to extract html, and ensure the correct data is extracted\n",
        "- learn about different ways to implement sentiment analysis depending on the context of the problem\n",
        "\n",
        "## Introduction\n",
        "\n",
        "[Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) is a way to figure out how people feel about something based on their words. For example, it can help us understand if a movie review is positive or negative, or if people are excited or unhappy about a product.\n",
        "\n",
        "In this notebook, you'll learn how to use a Python library called NLTK to perform sentiment analysis. We’ll also explore how to get data from websites and make sure we’re using the right information. Finally, you'll see how sentiment analysis can be applied in different situations to better understand opinions and feelings expressed in text.\n",
        "\n",
        "We'll begin by importing the necessary libraries and downloading a sentiment analysis model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-Moz1V1z0FB"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnpKPtouz0FC"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pg_ehu0z0FD"
      },
      "source": [
        "Now we can try some sentiment analysis. Below are three sentences that are happy, neutral, or negative, let's see how our model interprets each sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx7C94_Oz0FE"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "sentences = [\n",
        "    \"I am very extremely happy today because I scored an high score on my math test! I am feeling ecstatic!\",\n",
        "    \"I am feeling okay today because I scored an average score on my science exam. I feel decent.\",\n",
        "    \"I am feeling very sad today because I scored an low score on my history exam today. This sucks!\"\n",
        "    ]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "    print(f\"Sentiment Scores: {sid.polarity_scores(sentence)}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYM4-CLOz0FE"
      },
      "source": [
        "In general, our model appears to have generally assessed each sentence correctly. One thing to note though is that it appears that our model tends to rate sentences neutrally (`neu`) more often than swing towards `pos` or `neg`. We can keep this in mind in our future uses of this mode.\n",
        "\n",
        "## Book Chapters\n",
        "\n",
        "Next we will try some sentiment analysis from a book that we will download from [Project Gutenberg](https://www.gutenberg.org). We are going to use a public domain fiction book about basketball, called [The Girls of Central High at Basketball; Or, The Great Gymnasium Mystery](https://www.gutenberg.org/ebooks/37912)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gutenberg_text_link = 'https://www.gutenberg.org/cache/epub/37912/pg37912.txt'\n",
        "\n",
        "r = requests.get(gutenberg_text_link) # get the online book file\n",
        "r.encoding = 'utf-8' # specify the type of text encoding in the file\n",
        "book = r.text.split('***')[2] # get the part after the header\n",
        "book = book.replace(\"’\",\"'\").replace(\"“\",'\"').replace(\"”\",'\"') # replace any 'smart quotes'\n",
        "book_title = r.text[r.text.index('Title:')+7:r.text.index('Author:')-4] # find the book title\n",
        "\n",
        "chapter_list = [] # create a list to hold the chapter texts\n",
        "for chapter in book.split('CHAPTER'):\n",
        "    if len(chapter)>500: # so that we are getting actual book chapters\n",
        "        chapter_text = chapter.replace('\\r',' ').replace('\\n',' ') # delete the 'new line' characters\n",
        "        chapter_list.append(chapter_text) # add the chapter to the list\n",
        "chapters = pd.DataFrame(chapter_list, columns=['Chapter Text']) # create a data frame from the list\n",
        "chapters['Chapter'] = chapters.index+1 # add a column with the chapter number\n",
        "chapters = chapters[['Chapter', 'Chapter Text']] # reorder the columns\n",
        "chapters['Chapter Length'] = chapters['Chapter Text'].apply(len) # add a column with the length of each chapter\n",
        "chapters"
      ],
      "metadata": {
        "id": "82pZjOrZ6tcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the book downloaded and split into chapters, we can calculate the average sentiment of each chapter."
      ],
      "metadata": {
        "id": "tAyo_4tl6x1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chapters['Negative'] = chapters['Chapter Text'].apply(lambda text: sid.polarity_scores(text)['neg'])\n",
        "chapters['Neutral'] = chapters['Chapter Text'].apply(lambda text: sid.polarity_scores(text)['neu'])\n",
        "chapters['Positive'] = chapters['Chapter Text'].apply(lambda text: sid.polarity_scores(text)['pos'])\n",
        "\n",
        "chapters"
      ],
      "metadata": {
        "id": "buqXkWx-62tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can visualize the sentiment by chapter."
      ],
      "metadata": {
        "id": "TD53zgou7tlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "px.line(chapters, x='Chapter', y=['Negative','Positive'], title=f'Sentiment Analysis of {book_title}')"
      ],
      "metadata": {
        "id": "fsWzR_aW7yJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiZI2GODz0FE"
      },
      "source": [
        "## Webscraping\n",
        "\n",
        "**Webscraping** is a technique used to automatically gather data from websites by accessing and extracting information from websites.\n",
        "\n",
        "It often involves using tools or scripts to navigate websites to pull out specific data like text, images, or links.\n",
        "\n",
        "In our case, we'll be using [asapsports](https://www.asapsports.com/) to extract the 2024 NBA finals interviews between the Boston Celtics and the Dallas Mavericks. Let's start by finding the interview for the Dallas Mavericks, the team who lost the NBA championship\n",
        "\n",
        "**Note:** For your own implementation of projects, you *DO NOT* have to use web-scraping to extract information. Webscraping involves understanding HTML which is separate from Python. Instead, you can simply copy and paste the string/text you'd like to perform sentiment analysis on into Python directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7B8e3_Yz0FE"
      },
      "outputs": [],
      "source": [
        "luka_url = \"https://www.asapsports.com/show_interview.php?id=198323\"\n",
        "\n",
        "response = requests.get(luka_url)\n",
        "luka_html = response.content\n",
        "soup = BeautifulSoup(luka_html, \"html.parser\")\n",
        "luka_paragraphs= soup.find_all('p')\n",
        "temp = [para.get_text(strip=True) for para in luka_paragraphs]\n",
        "luka_info_combined = \"\\n\".join(temp)\n",
        "print(luka_info_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAk8oHMuz0FF"
      },
      "source": [
        "## Sentiment Analysis\n",
        "\n",
        "Now that we've obtained the interview for the Dallas Mavericks (primarily Luka Dončić) let's perform some sentiment analysis on his speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ih2AlR4z0FF"
      },
      "outputs": [],
      "source": [
        "luka_score = sid.polarity_scores(luka_info_combined)\n",
        "luka_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aywyZ4vz0FF"
      },
      "source": [
        "Surprisingly, we see that our model has rated Luka's speech as neutral and slightly positive compared to negative.\n",
        "\n",
        "However, in our text, we've also included Luka's interviewer. Let's try to separate Luka's interviewer and his own dialogue to get a better understanding of his speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpLCR4P3z0FF"
      },
      "outputs": [],
      "source": [
        "interviewer_text = []\n",
        "luka_text = []\n",
        "current_speaker = None\n",
        "\n",
        "lines = luka_info_combined.split('\\n')\n",
        "for line in lines:\n",
        "    if line.startswith('Q.'):\n",
        "        current_speaker = 'interviewer'\n",
        "        interviewer_text.append(line[2:].strip())\n",
        "    elif line.startswith('LUKA DONCIC:'):\n",
        "        current_speaker = 'luka_doncic'\n",
        "        luka_text.append(line[len('LUKA DONCIC:'):].strip())\n",
        "    else:\n",
        "        if current_speaker == 'interviewer':\n",
        "            interviewer_text[-1] += ' ' + line.strip()\n",
        "        elif current_speaker == 'luka_doncic':\n",
        "            luka_text[-1] += ' ' + line.strip()\n",
        "\n",
        "interviewer_text = ' '.join(interviewer_text)\n",
        "luka_text = ' '.join(luka_text)\n",
        "\n",
        "print(\"Interviewer:\")\n",
        "print(interviewer_text)\n",
        "print(\"Luka Dončić:\")\n",
        "print(luka_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqMHktMhz0FF"
      },
      "source": [
        "Now that we've separated Luka's text, let's perform sentiment analysis on both texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8szqfiuaz0FF"
      },
      "outputs": [],
      "source": [
        "luka_interviewer = sid.polarity_scores(interviewer_text)\n",
        "print(f\"Luka Interviewer Score: {luka_interviewer}\")\n",
        "\n",
        "luka_individual = sid.polarity_scores(luka_text)\n",
        "print(f\"Luka Score: {luka_individual}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OFArkGlz0FG"
      },
      "source": [
        "Looking at both texts, we see that we still have a dominantly presence of neutrality. We do see that Luka's score is slightly more negative compared to his interviewer, however, this amount appears to be too slight to be considered a major difference.\n",
        "\n",
        "Let's also find the text of the Boston Celtics, the team who won the NBA championship."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPmjzq3oz0FG"
      },
      "outputs": [],
      "source": [
        "jayson_tatum_url = 'https://www.asapsports.com/show_interview.php?id=198332'\n",
        "\n",
        "response = requests.get(jayson_tatum_url)\n",
        "tatum_html = response.content\n",
        "soup = BeautifulSoup(tatum_html, \"html.parser\")\n",
        "tatum_paragraphs= soup.find_all('p')\n",
        "temp = [para.get_text(strip=True) for para in tatum_paragraphs]\n",
        "tatum_info_combined = \"\\n\".join(temp)\n",
        "print(tatum_info_combined)\n",
        "\n",
        "tatum_score = sid.polarity_scores(tatum_info_combined)\n",
        "tatum_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WRF_NY-z0FG"
      },
      "source": [
        "Similarly to Luka, Jayson Tatum appears to be overall neutral in tonality. Let's also separate his interview to get a more accurate analysis on his emotions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yud7H4ISz0FG"
      },
      "outputs": [],
      "source": [
        "interviewer_text = []\n",
        "tatum_text = []\n",
        "current_speaker = None\n",
        "\n",
        "lines = tatum_info_combined.split('\\n')\n",
        "for line in lines:\n",
        "    if line.startswith('Q.'):\n",
        "        current_speaker = 'interviewer'\n",
        "        interviewer_text.append(line[2:].strip())\n",
        "    elif line.startswith('JAYSON TATUM:'):\n",
        "        current_speaker = 'jayson_tatum'\n",
        "        tatum_text.append(line[len('JAYSON TATUM:'):].strip())\n",
        "    else:\n",
        "        if current_speaker == 'interviewer':\n",
        "            interviewer_text[-1] += ' ' + line.strip()\n",
        "        elif current_speaker == 'jayson_tatum':\n",
        "            tatum_text[-1] += ' ' + line.strip()\n",
        "interviewer_text = ' '.join(interviewer_text)\n",
        "tatum_text = ' '.join(tatum_text)\n",
        "\n",
        "print(\"Interviewer:\")\n",
        "print(interviewer_text)\n",
        "print(sid.polarity_scores(interviewer_text))\n",
        "print(\"---\")\n",
        "print(\"Jayson Tatum:\")\n",
        "print(tatum_text)\n",
        "print(sid.polarity_scores(tatum_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlG3eBsaz0FH"
      },
      "source": [
        "Looking at our separated scores, we see that both are still overly neutral in nature, however, Tatum does appear to have a larger `pos` score compared to his interviewer. This should be natural, as Tatum appears to be happier in his interview as he was the team who won the NBA championship.\n",
        "\n",
        "## Your Turn\n",
        "\n",
        "Now that you've seen some examples of sentiment analysis from pasted text, a downloaded book, and from web-scraped text, try it with some of your own text, or a different book from [Project Gutenberg](https://www.gutenberg.org), in the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\n",
        "\n",
        "sid.polarity_scores(text)"
      ],
      "metadata": {
        "id": "R40UIALR5sQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c36envRLz0FH"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "**Sentiment analysis** is a powerful tool for understanding people's emotions and opinions from text. By using techniques from the Natural Language Toolkit, we can automatically determine whether a piece of text expresses positive, negative, or neutral sentiments.\n",
        "\n",
        "This ability to analyze and interpret large volumes of text data can provide valuable insights for various applications. As you explore sentiment analysis, remember that it can be tailored to different problems, such as customer feedback or social media monitoring."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Data Dunkers License](https://github.com/Data-Dunkers/lessons/blob/main/images/bottom-banner.jpg?raw=true)](https://github.com/Data-Dunkers/lessons/blob/main/LICENSE.md)"
      ],
      "metadata": {
        "id": "RqI5if7v5eAC"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}