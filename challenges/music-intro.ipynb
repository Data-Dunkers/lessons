{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DataDunkers.ca Banner](https://github.com/Data-Dunkers/lessons/blob/main/images/top-banner.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music\n",
    "\n",
    "<table><tr>\n",
    "<td style=\"font-size:8px;\"> <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Treble_a.svg/1920px-Treble_a.svg.png\" alt=\"Musical Staff\" style=\"width: 350px;\"/><br><a href=\"https://en.wikipedia.org/wiki/Musical_note#/media/File:Treble_a.svg\">By Dbolton - Own work, CC0, https://commons.wikimedia.org/w/index.php?curid=17813642</a></td>\n",
    "<td> <img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\" style=\"width: 650px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Music is an art loved by many people around the world, and it has been an important part of people's life.\n",
    "\n",
    "On a regular day, you might be listening to your artist or trying to play your favourite songs. In this hackathon notebook let's try to find out more about the most popular songs and what they have in common. Hopefully you will find some interesting insights that might be difficult to determine otherwise, while learning some new coding skills.\n",
    "\n",
    "[Spotify](https://en.wikipedia.org/wiki/Spotify), an audio streaming platform, has a huge database of songs and information about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "Run the cell below to import required Python libraries and a dataset of about 40,000 songs that has been [exported from Spotify](https://developer.spotify.com/documentation/web-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "music = pd.read_csv('https://raw.githubusercontent.com/Data-Dunkers/lessons/refs/heads/main/challenges/music-data.csv')\n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Columns\n",
    "\n",
    "Let's have a look at the columns in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in music.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know which columns are there in the dataset, but what do those columns refer to?\n",
    "\n",
    "**Danceability**: How suitable a track is for dancing. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "\n",
    "**Energy**: A perceptual measure of intensity and activity that ranges between 0 to 1. Typically, energetic tracks feel fast, loud, and noisy.\n",
    "\n",
    "**Key**: The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.\n",
    "\n",
    "**Loudness**: The average loudness of a track in decibels (dB). Values typically ranges between -60 and 0 db.\n",
    "\n",
    "**Mode**: The modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
    "\n",
    "**Speechiness**: Indicates the presence of spoken words in a track. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech while below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "\n",
    "**Acousticness**: A confidence measure indicating whether the track is acoustic. Value of 1 represents highest confidence.\n",
    "\n",
    "**Instrumentalness**: Predicts whether a track contains no vocals. The closer the value is to 1.0, the greater likelihood the track contains no vocal content.\n",
    "\n",
    "**Liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n",
    "\n",
    "**Valence**: A measure to describe the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "**Tempo**: The overall estimated tempo (speed or pace) of a track in beats per minute (BPM).\n",
    "\n",
    "**duration_ms**: The duration of the track in milliseconds.\n",
    "\n",
    "**time_signature**: An estimated overall time signature of a track. The time signature is a notational convention to specify how many beats are in each bar (or measure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Adding New Columns\n",
    "\n",
    "We can add a new column to show the duration of the track in seconds instead of milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "music['duration_s'] = music['duration_ms']/1000\n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add a column of links to the tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music['link'] = 'https://open.spotify.com/track/' + music['track_id']\n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `release_date` column, we can see that for some songs it is just the year and for some it is a [standard date](https://www.iso.org/iso-8601-date-and-time-format.html). Let's create a new column called `release_year` that is just the first four characters of the `release_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music['release_year'] = music['release_date'].str[:4].astype(int)\n",
    "music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Song Duration \n",
    "\n",
    "Let's visualize the song lengths over the years to see if there is anything strange in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(music, x='release_year', y='duration_s', title='Song Duration Over Time', hover_data=['artist', 'track', 'link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to eliminate some of the outliers, for example songs released before 1950."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_music = music[music['release_year'] >= 1949]\n",
    "px.scatter(new_music, x='release_year', y='duration_s', title='Song Duration Over Time', hover_data=['artist', 'track', 'link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or only look at songs from the 1990s with a duration less than 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_90s_music = music[(music['release_year']>1989) & (music['release_year']<2000) & (music['duration_s']<10*60)]\n",
    "px.scatter(short_90s_music, x='release_year', y='duration_s', title='Song Duration Over Time', hover_data=['artist', 'track', 'link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see if the average `danceability` has changed over time in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_danceability = music.groupby('release_year')['danceability'].mean()\n",
    "px.line(average_danceability, title='Average Danceability Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course for years where there are not a lot of songs in our in our dataset, the average will not be a useful value.\n",
    "\n",
    "Let's look instead at another dataset containing the top 50 tracks from 2010 to 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music2 = pd.read_csv('https://raw.githubusercontent.com/Data-Dunkers/lessons/refs/heads/main/challenges/music-data-top-50-2010-2019.csv')\n",
    "px.line(music2.groupby('year')['danceability'].mean(), title='Top 50 Average Danceability Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is a relationship between `energy` and `danceability` in either dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(music, x='energy', y='danceability', title='Energy vs Danceability', hover_data=['artist', 'track'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(music2, x='energy', y='danceability', title='Energy vs Danceability for Top 50', hover_data=['artist', 'title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also explore and visualize other song features from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to embed a YouTube video in a notebook using the video ID from the link. For example, if the video is at `https://www.youtube.com/watch?v=dQw4w9WgXcQ` then we can use the code below to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('dQw4w9WgXcQ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the [next notebook](music-challenge.ipynb) to continue your own analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Data Dunkers License](https://github.com/Data-Dunkers/lessons/blob/main/images/bottom-banner.jpg?raw=true)](https://github.com/Data-Dunkers/lessons/blob/main/LICENSE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
